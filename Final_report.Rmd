---
title: "Final_report"
author: "R.Riddell"
date: "26/04/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(janitor)
library(broom)
```
# Introduction
## Background
Basketball is a team sport composed of 5 players per team and was invented around 1891 by James Naismith^(1)^. The game has evolved signifntly since then and is now a very popular and lucaratcive sport internationalal. Both players and organistions are able to earn a signfinat amount of money through sponsorship and media rights^(2)^. In an attempt to even the financial playing field a the modern salary cap was introduced in the 1984-85 season with a \$3,600,00 cap. The salary system has grown into a very complex and regualted system that ensures organisation's aren't able to spend any money they want on players. The NBA salary system is descriped as a soft cap due to a system of salary cap exceptions and is based off teams basketabll related income. Due to the NBA operating a soft cap it means their can be some range in what salary can be committed to players. Organisations needs to very strategic in the way they structure player contract in order to maximse the money they spend^(3).^ \n

## Scenario
The Chicago Bulls finished 27 from 30 teams in the most recent season, totally 22 wins from 82 games. Their point production was 104.5 points per game which ranks as the 26 out of 30 teams. As opposed to the Milwaukee Bucks who excelled with 60 wins and an average points per game of 118.1. The Chicago Bulls are coming into this season with an available \$118 million dollars for contracting players, which is 26 out of 30 compared to the rest of the league. Where the Milwaukee Bucks had \$131 million budget, showing the disapartity on avaiable budgets. \n

## Aim
The aim of this report is to flag and identify players that will enhance the probabaility of the Chicago Bulls winning more games than last season. \n

## Justification
The reason this report is nesscacry is shown by the discrepency between what can be spent on players and what the Chicago Bulls can spend on players. This discrepenacy highlights that the Chicago Bulls are not able to just recruit any player and instead must be strategic to ensure they buy players that will have a positive influence on winning for their team. \n


# Wrangling data
The descriptions and infomrtion about the data used in this report can be found at [Data Descriptions](https://github.com/RobertRiddell/Final-Project_10157/tree/main/data-descriptions). \n

## Player Data
```{r include=F}
# Running the cleaning scripts from the funs folder to seperate the cleaninig and model analysis
source("funs/clean_player-stats.R")
obs_var1 <- dim(player_stats) 
num_players <- length(unique(player_stats$player_name))
two_team_players <- player_stats %>% 
  group_by(player_name, age) %>% 
  count() %>% 
  filter(n >1) %>% 
  pull %>%  
  length()


```
The player data consited of `r obs_var1[2]` variables and `r obs_var1[1]` observations tabulated fromthe 2018/19 season. This data set included `r num_players` unique players which is assumed to be all of the active players in the league.

The data relavant to players was read in and cleaned in accordance with the tidyr principles https://tidyr.tidyverse.org/articles/tidy-data.html. \n
The first issue that needed investigating was when a player had been traded during the season had both the statistcis for the teams they had played for and a total row for all their statistics. There was `r two_team_players` players affected by this issue.  To resolve this issue the total row for affected players was removed from the data, leaving some players with multiple rows. \n

The next issue noted was some players had different positions listed, such as Thon Maker who was listed as a PF for Detroit and a Center for Milwakee. It was decided that the player would be assigned the poistion they played the most games at. To do this the number of games was totalled for all players and a new postion list was tabulated to overwrite the old positions. This function reassigned the players poistion on all observations to teh position they played most during the season. \n

These players also had a secondary issue where they had different teams listed due to being traded. This issue was solved using the same method as the positions, where the player was assigne th etam they played the most amount of games from. The player data was then grouped under each name so each player only had one observation in the dataset. \n

After grouping the data together there was some calculation errors discovered in some of the field goal percentage statistics. These issues arose as some filed goal values presenetd as NA and some attempt values were 0 so after the field goal calucaltion were completed the resultant figure was invalid. The second issed occured through a zero division error as there was not attempted shots so therofore the divsion resulted in an NA instead of a zero. During the recalcuation the effective field goal statistics was also included in the data, this statistics takes into account the extra worth of a 3 point percentage. The effective field goal is calcualted by using the formula  $(FG + 0.5 * 3P) / FGA$^(4)^. \n

## Team Data
```{r include=F}
# Running the cleaning scripts from the funs folder to seperate the cleaninig and model analysis
source("funs/clean_team-stats.R")
obs_var2 <- dim(team_stats)
```
The team data was sourced from three different sources, two differnet set of statistics and another seperate file that contained team payroll information. The statistical information was for each team and collected form the 2018/19 season. The two sets of team statistics were combined with the team based statistics such as pace and offensice rating removed as they were adjudged to not be applicable for player selection. The payroll data was then added to the team based data leaving the data with `r obs_var2[2]` variables and `r obs_var2[1]` observations.


#Exploratory analysis
This section should document your exploratory data analysis and may include but is not limited to:
- checking for errors and missing values within the datasets
- checking the distribution of variables
- checking for relationships between variables, or differences between groups
- justification for decisions made about data modelling
Note that this section and the data cleaning section may be an iterative process, as you might find things about the data that need to be 'cleaned up' once you have explored the data further. 

## Distribution
```{r include=F}
tm_stats <- read_csv("data/processed/cleaned_team-stats.csv")
sum(is.na(tm_stats))

source("funs/gg_hist.R")

numeric_vars <- tm_stats %>% 
  select(where(is.numeric),- c(w,g)) %>% 
  names(.)

for (i in seq_along(numeric_vars)) {
  print(gg_hist(tm_stats, numeric_vars[i]))
}

```

After looking at a distribution of all numeric variables a sleection were identfied as the most normal in overall distribution. From the seven selected variables the correlation on how many game the team won versus the variable was calculated, these correlations can be seen in table 1. As seen in table 1 the statitics that returned the best correlation with winning game was points. The distribution for pts is displayed in Figure 1, the distribution is not a perfect normal distribution and could be decsibed as bi-model with a right hand skew. Using the combination of the distribution and best correlation the poinst statistic has been chosen to be the best predictor of won game. 
```{r echo=FALSE}
f_tr <- round(cor(tm_stats$w, tm_stats$f_tr),2)
pf <- round(cor(tm_stats$w, tm_stats$pf),2)
blk <- round(cor(tm_stats$w, tm_stats$blk),2)
trb <- round(cor(tm_stats$w, tm_stats$trb),2)
drb <- round(cor(tm_stats$w, tm_stats$drb),2)
ft_percent <- round(cor(tm_stats$w, tm_stats$ft_percent),2)
fta <- round(cor(tm_stats$w, tm_stats$fta),2)
pts <- round(cor(tm_stats$w, tm_stats$pts),2)

cor_w <- rbind(f_tr, pf, blk, trb, drb, ft_percent, fta, pts)
cor_w <- as.data.frame(cor_w)
cor_w <- rownames_to_column(cor_w, "Statistic")
cor_w <- rename(cor_w, "Correlation" = V1)
knitr::kable(cor_w,caption = "Table 1.")

ggplot(tm_stats, aes(pts)) +
  geom_histogram(colour = '#048BA8', fill = '#16DB93', alpha = 0.8, binwidth = 150) +
  labs(title = "Distribution of points",
       x = "Total Points",
       caption = "Figure 1") + 
  theme_bw()

```


## Relationships
In Figure 2 the relationship between points and winning games has been presented to reinforce the decsion that points will be the best indication for games won. Therefore points will be targeted as the response variable and the other varibles will be used to predict it. In an attempt to standardise the variables all have been converted to per game amounts  as opposed to season total amounts. 
```{r echo=FALSE}
ggplot(tm_stats, aes(w, pts)) +
  geom_point() + 
  geom_smooth(method = "lm", se = F, linetype = "dashed", colour = "red") +
  labs(title = "Relatioship between Wins and Points",
       x = "Wins",
       y = "Points",
       caption = "Figure 2") +
  theme_bw()
cor(tm_stats$w, tm_stats$pts)
```
All explanatory variables were assesed visually for their relationship with points and the correlation coefffinet was calcualted. Through teh iterative priocess of modelling some variables were also removed at this stage due to multicolinearty, a poor linear relationship in the model or a slope confidence interval that stradded zero. \n

These varible were removed due to a low correlation coefffinet of between -0.2 to 0.2:
*2pa
*mp
*tov
*pf
*ft_percent
*stl
*orb

These varible were removed due to a multicolinearty:
*e_fg_percent
*ft_fga
*fg
*x3p
*x3p_ar
*ft
*fta
*drb
*fg_percent
*x2p_percent
*x3p_percent

These varible were removed due to a poor linear relationship in the model:
*blk

These varible were removed due to an unreliable confidence interval on their slope prediction:
*x3pa
*x2p
*trb
*ast

```{r include=F}
# convert stats to per game
tm_stats <- tm_stats %>% 
  mutate(mp = mp/g,
            fg = fg/g,
            fga = fga/g,
            fg_percent = fg/fga,
            x3p = x3p/g,
            x3pa = x3pa/g,
            x3p_percent = x3p/x3pa,
            x2p = x2p/g,
            x2pa = x2pa/g,
            x2p_percent = x2p/x2pa, 
            ft = ft/g,
            fta = fta/g,
            ft_percent = ft/fta,
            orb = orb/g,
            drb = drb/g,
            trb = trb/g,
            ast = ast/g,
            stl = stl/g,
            blk = blk/g,
            tov = tov/g,
            pf = pf/g,
            pts = pts/g)

team <- tm_stats$team

# variables removed as they will not add to predicting points scored
tm_stats <- tm_stats %>% 
  select(!c(g, rk,team, team_id, salary, w))

source("funs/gg_scatter.R")

numeric_vars <- tm_stats %>% 
  select(where(is.numeric),- pts) %>% 
  names(.)

for (i in seq_along(numeric_vars)) {
  print(gg_scatter(tm_stats, numeric_vars[i]))
}

tm_stats %>% 
  select(is.numeric) %>% 
  corrr::correlate() %>% 
  corrr::focus(pts) %>%
  arrange(pts) 

# remove low correlations between -0.2 and 0.2
tm_stats <- tm_stats %>% 
  select(!c(x2pa, mp, tov, pf, ft_percent, stl, orb))

# Remove obvious variables that impact each other
GGally::ggcorr(tm_stats, method = c('pairwise','spearman'), 
               size = 2 )

tm_stats <- tm_stats %>% 
  select(!c(e_fg_percent, ft_fga, fg, x3p, x3p_ar, ft, fta, drb, fg_percent, x2p_percent, x3p_percent))

# removed as it shows low linear relationship in the car::avPlots(fit)
tm_stats <- tm_stats %>% 
  select(!blk)

# Removes as the confint for the slope was -1.043498e-03	4.461750e-02 
tm_stats <- tm_stats %>% 
  select(!c(x3pa, x2p, trb, ast))

```

## Justification
As points has a resonably normal distribution and a correlation coefficent of 0.66 it is belive that it will provide the predictor for overall games win. It is possible thats another statistic that has a better distribution would model better in the data and be more predictable but as the overall goal is too increase wins it is important that the statistic chosen has strong relationship to winning 

#Data modelling and results
## Modelling
Through the previous cleaning and explaortaoion of the data the best explantory variables have been included in the multiple minear regression model. These varibles include F-tr,ts_percent and fga. The relavant assumptions have been conducted on the data to ensure all varibles meet the requirement of a multiple minear regression model.

## Assumptions
```{r include=FALSE}
# Model
fit <- lm(pts ~ ., tm_stats)
tidy(fit, conf.int = T)
summary(fit)
```

Continous Varibles
* The reponse varible in points is a continous variable and all explanatory variables are also continous
Linear relationship
* There is an obvious linear relationship between all explanatory variables and points. This has been confirmed used the car package and avPlots function
```{r echo=FALSE}
# Linearity
car::avPlots(fit)
```
Outliers
* The outlier plot in Figure 3 shows no obvious outliers
```{r echo=FALSE}
#outliers
std_res <- rstandard(fit)
points <- 1:length(std_res)
ggplot(NULL, aes(points, std_res)) +
  geom_point() +
  ylim(c(-4,4)) +
  geom_hline(yintercept = c(-3,3) , colour = "red", linetype = "dashed") + 
  labs(title = "Residual plot",
       x = "",
       y = "Residuals",
       caption = "Figure 3") +
  theme_bw()

# no obvious outliers
```

```{r include=FALSE}
# Leverage points
tmpdf <- tm_stats 
tmpdf$hats <- hatvalues(fit)
lev_labels <- if_else(tmpdf$hats >= 0.4, paste(team), "")

ggplot(tmpdf, aes(points, hats)) +
  geom_point() +
  ggrepel::geom_text_repel(aes(label = lev_labels), colour = "navy")


# Influence
cook <- cooks.distance(fit)
cook_labels <- if_else(cook >= 1, paste(team), "")

ggplot(NULL, aes(points, cook)) +
  geom_point() +
  ggrepel::geom_text_repel(aes(label = cook_labels), colour = "navy")


```


Independence
* Using the car package and the durbinWatsonTest package a Durbin Watson statistic of 2.28 is returned which indicates a normal range and shows the model is independent.
```{r}
# Independence
car::durbinWatsonTest(fit)
# can range from 0 - 4
# 2 means observations are independent

```

Homoscedasticity
* To assess the homoscedasticity the predicted values are plotted against the residuals. Ideally this figure 4 will show a random spread of point which will indicate homoscedasticity.

```{r}
# Homoscedasticity
res <- residuals(fit)
fitted <- predict(fit)
res_labels <- if_else(res >= .1 | res <= -.12, paste(team), "")
ggplot(NULL, aes(fitted, res)) +
  geom_point() +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  ggrepel::geom_text_repel(aes(label = res_labels), colour = "navy") +
    labs(title = "Predicted Values against Residuals",
       x = "Preditec",
       y = "Residuals",
       caption = "Figure 4") +
  theme_bw()


# ideally a random spread with no clear pattern
```

Normally distributed
* To assess the distriutionof the model the normality of residuals can be viewed. By looking at a histogram of the residuals and a qqplot it can be seen that teh resiudals appear normal 
```{r}
# Normality of residuals

ggplot(NULL, aes(res)) +
  geom_histogram(binwidth = .07)

ggplot(NULL, aes(sample =res)) +
  stat_qq() +
  stat_qq_line()

```

## Model output
The model output shows an adjetsed R sqaure value of 0.99 which indicates a very accuarate model but may be an indiation of overfitting in a small dataset. The slope coeffients are positive values which indicates as they increase so will points. For instance, teh slope coeffient for fga is 1.23 which shows that for every 1.23 shots taken per game there will be 1 point return when all other values are held constant.
```{r include=FALSE}
tidy(fit, conf.int = T)
summary(fit)
```
```{r include=FALSE}
# multicolinearty
cor_mat <- tm_stats %>% 
  select(where(is.numeric)) %>% 
  cor(., method = 'spearman')

# select the variables that display multicolinearty above 0.8
cor_features <- caret::findCorrelation(cor_mat, cutoff = 0.8, names = T, exact = FALSE)

# Variance Inflation Factor
car::vif(fit)
sqrt(car::vif(fit))

tm_stats
```
# Player recommendations
This section will be the key part that is presented to the general manager. Here you should present your recommendations for the best five starting players, but also think about what other important information they would want to know, and how it is best to present that information to them. 
```{r}
team_mins <- read_csv("data/processed/cleaned_team-stats.csv")

min_per_game <- team_mins %>% 
  group_by(team) %>% 
  summarise(ave_mins = mean(mp)/ g) %>% 
  pull %>% 
  mean

player_stats <- read_csv("data/processed/cleaned_player-stats.csv")

#players <- player_stats %>% 
  #group_by(player_name) %>% 
  #summarise(G = sum(mp)/ min_per_game,
            #f_tr = (fta/fga),
            #ts_percent = pts / ((.44*fta + fga)*2),
            #fga = sum(fga)/G,
            #x3pa = sum(x3pa)/G,
            #x2p = sum(x2p)/G,
            #trb = sum(trb)/G,
            #ast = sum(ast)/G,
            #blk = sum(blk)/G,
            #MP = sum(mp)) %>% 
  #select(-G) 

players <- player_stats %>% 
  group_by(player_name) %>%
  summarise(G = sum(mp)/ min_per_game,
            f_tr = (fta/fga),
            ts_percent = pts / ((.44*fta + fga)*2),
            fga = sum(fga)/G)


```

```{r}
player_stats <-  player_stats %>% 
  select(player_name, age, Pos, Tm, mp)

player_salary <- read_csv("data/raw/2018-19_nba_player-salaries.csv")

player_stats <- left_join(player_stats, player_salary, by= "player_name")

players <- mutate(players, exp_pts = predict(fit, newdata = players))

players <- players %>% 
  select(player_name, exp_pts)

player_stats <- left_join(player_stats, players, by = "player_name")

player_stats %>% 
  select(player_name, age, mp, Pos, salary, exp_pts) %>% 
  filter(mp > 300 & Pos =="PF") %>% 
  arrange(-exp_pts) 

player_stats %>% 
  select(player_name, age, mp, Pos, salary, exp_pts) %>% 
  filter(mp > 300) %>% 
  mutate(salary_points_ratio = exp_pts/salary) %>% 
  arrange(-salary_points_ratio) %>% 
  filter(Pos == "C")
# Jordan McRae	      27	333	  SG	77250	    116.136416	
# Christian Wood      23	502	  PF	1512601	  159.108397	
# Spencer Dinwiddie	  25	1914	PG	1656092	  141.702753
# Thomas Bryant	      21	1496	C	  1378242	  124.43076		
# Caris LeVert	      24	1063	SF	1702800	  126.46152	

# 77,250 + 1,512,601 + 1,656,092 + 1,378,242 + 1,702,800 = 6,326,985
# 116.136416 + 159.108397 + 141.702753 + 124.43076 + 126.46152 = 667.8398

player_stats %>% 
  select(player_name, age, mp, Pos, salary, exp_pts) %>% 
  filter(mp > 300) %>% 
  arrange(-exp_pts) %>% 
  filter(Pos == "C")
# D'Angelo Russell	  22	2448	PG	7019698	  175.12603
# Devin Booker	      22	2242	SG	3314365	  177.381624
# Kawhi Leonard	      27	2040	SF	23114066	180.49953
# Christian Wood	     23	502	  PF	1512601	  159.10840
# Karl-Anthony Towns	23	2545	C	  7839435	  170.98054

# 7,019,698 + 3,314,365 + 23,114,066 + 1,512,601 + 7,839,435 = 42,800,165
# 175.12603 + 177.381624 + 180.49953 + 159.10840 + 170.98054 = 863.0961

player_stats %>% 
  select(player_name, age, mp, Pos, salary, exp_pts) %>% 
  filter(mp > 300) %>% 
  arrange(-exp_pts) %>% 
  filter(Pos == "C")
# James Harden	          29	2867	PG	30570000	219.13162
# Devin Booker	          22	2242	SG	3314365	  177.381624
# Kawhi Leonard	          27	2040	SF	23114066	180.49953
# Giannis Antetokounmpo	  24	2358	PF	24157304	188.13349
# Joel Embiid	            24	2154	C	  25467250	186.03184

# 30570000 + 3314365 + 23114066 + 24157304 + 25467250 = 106,622,985
# 219.13162 + 177.381624 + 180.71463 + 188.13349 + 186.03184 = 951.3932


```

# Summary 
Provide a brief summary which describes the key points and findings from your project. It will also be important to acknowledge any limitations of your model and overall approach to answering the question asked of you by the general manager.

Reference List
Provide a reference list of any sources you used in the development of your report and justification of your arguments. Please use the Vancouver reference style (Links to an external site.) for the reference list and in-text references. 

1.	Donald LW, Logan RG, Mokray WG. Basketball. In: Encyclopedia Britannica. 2021.
2.	Reiff N. How the NBA makes money [Internet]. Investopedia.com. 2020 [cited 2021 May 3]. Available from: https://www.investopedia.com/articles/personal-finance/071415/how-nba-makes-money.asp
3.	CBA Breakdown [Internet]. Cbabreakdown.com. [cited 2021 May 3]. Available from: https://cbabreakdown.com/salary-cap-overview
4. Page B, Page B. Glossary | Basketball-Reference.com [Internet]. Basketball-Reference.com. 2021 [cited 3 May 2021]. Available from: https://www.basketball-reference.com/about/glossary.html#:~:text=eFG%25%20%2D%20Effective%20Field%20Goal%20Percentage,a%202%2Dpoint%20field%20goal

 